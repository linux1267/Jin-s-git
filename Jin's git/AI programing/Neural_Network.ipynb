{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85262529",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron with MNIST handwritten digits classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8eedf",
   "metadata": {},
   "source": [
    "## 1. Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315ebfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798bac6b",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9880ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.11.0  Device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5590af",
   "metadata": {},
   "source": [
    "## 3. MNIST 데이터 다운로드 (Train data와 Test data 분리하기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00908077",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17579718",
   "metadata": {},
   "source": [
    "## 4. 첫번째 batch 데이터의 크기와 타입을 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d2818b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ee4fa",
   "metadata": {},
   "source": [
    "# Loss 구하기 \n",
    "   forward propagation을 계산하는 함수 구현하기\n",
    "   \n",
    "   1) input layer (입력층), hidden layer (은닉층), output layer (출력층) 으로 이루어진 모델을 이용\n",
    "\n",
    "   2) 하나의 hidden layer (은닉층)만 이용 - 은닉층의 개수는 100개로 하세요\n",
    "\n",
    "   3) 모든 것은 tensor 계산으로만 할 것!! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdfc2da",
   "metadata": {},
   "source": [
    "## ReLU, one_hot_encoding, softmax, cross_entropy 구하기\n",
    "\n",
    "아래 코드는 각 함수가 맞는지 확인하기 위해서 만든 임의의 값입니다. \n",
    "각 함수가 작동을 잘하는지 확인해 보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f6bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.tensor([[1,-2,-4, 2, 5, 6, -3, -5, 0, 2],[2, -3, 4, 3, -1, -4, 3, 5, 2, -3]])\n",
    "true_label = torch.tensor([5,7])\n",
    "false_label = torch.tensor([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e322d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_func(outputs):  #0보다 큰 값이면 자기 자신의 값을 가지고 0보다 작다면 0을 가진다.\n",
    "    zero_tensor = torch.zeros(outputs.size())\n",
    "    final_outputs = torch.maximum(outputs, zero_tensor)\n",
    "\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2f287",
   "metadata": {},
   "source": [
    "ReLU 함수가 맞는지 test_data를 이용하여 맞추어 보자. 아래 함수의 결과는 어떻게 예상되는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfe43970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 2., 5., 6., 0., 0., 0., 2.],\n",
       "        [2., 0., 4., 3., 0., 0., 3., 5., 2., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU_func(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a8e3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(label):  #0부터 9까지 중에 숫자를 구하는 것이므로 크키가 10이고 답이 아닌 노드들은 0으로, 답인 노드는 1로 두어 loss를 구한다.\n",
    "                              #label값은 우리가 원하는 값\n",
    "    #one_hot_outputs = torch.sparse.torch.eye(10)\n",
    "    #one_hot_outputs = one_hot_outputs.index_select(0,label)\n",
    "    encode = torch.eye(10,10)\n",
    "    one_hot_outputs = encode[label]\n",
    "    \n",
    "    return one_hot_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd57e3",
   "metadata": {},
   "source": [
    "one_hot_encoding 함수가 맞는지 true_label, false_label을 이용하여 맞추어 보자. 아래 함수 결과는 어떻게 예상되는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e73e407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 9.9910e-01,\n",
      "         1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04],\n",
      "        [1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,\n",
      "         1.0000e-04, 9.9910e-01, 1.0000e-04, 1.0000e-04]])\n"
     ]
    }
   ],
   "source": [
    "# 검증을 위해 아래 4줄을 사용하면 됩니다. \n",
    "tl = one_hot_encoding(true_label)  \n",
    "print(tl)\n",
    "fl = one_hot_encoding(false_label)\n",
    "print(fl)\n",
    "\n",
    "# 나중을 위해서 사용될 코드 입니다. \n",
    "close_tl = tl.clone()\n",
    "close_tl[[0,1],true_label] -= 0.001\n",
    "close_tl[false_label] += 0.0001\n",
    "print(close_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23f07c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(outputs):\n",
    "    numerator = torch.exp(outputs - torch.max(outputs,axis=1)[0].view(-1,1))\n",
    "    denominator = torch.sum(numerator, axis=1).view(-1,1)\n",
    "    softmax = numerator/denominator\n",
    "    \n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36037c34",
   "metadata": {},
   "source": [
    "softmax 함수가 맞는지 test_data를 이용하여 맞추어 보자. 아래 함수의 결과는 어떻게 예상되는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "361e5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7643e-03, 2.3720e-04, 3.2102e-05, 1.2951e-02, 2.6012e-01, 7.0709e-01,\n",
      "         8.7262e-05, 1.1810e-05, 1.7527e-03, 1.2951e-02],\n",
      "        [2.8590e-02, 1.9264e-04, 2.1126e-01, 7.7716e-02, 1.4234e-03, 7.0868e-05,\n",
      "         7.7716e-02, 5.7425e-01, 2.8590e-02, 1.9264e-04]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = softmax(test_data)\n",
    "print(a)\n",
    "torch.sum(a,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e9c3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(outputs, labels):\n",
    "    \n",
    "    return torch.sum(-1*labels*torch.log(outputs),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff4cae",
   "metadata": {},
   "source": [
    "cross_entropy 함수가 맞는지 test_data를 이용하여 맞추어 보자. 아래 함수의 결과는 어떻게 예상되는가? tl, fl, close_tl을 이용하여 각각의 cross entropy를 구하고 그 값이 맞는지 확인하세요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9998c30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0009, 0.0009])\n",
      "tensor([9.2103, 9.2103])\n",
      "tensor([0.3466, 0.5547])\n",
      "tensor([8.3466, 3.5547])\n"
     ]
    }
   ],
   "source": [
    "ideal_result = cross_entropy(close_tl, tl)\n",
    "non_ideal_result = cross_entropy(close_tl,fl)\n",
    "\n",
    "print(ideal_result)\n",
    "print(non_ideal_result)\n",
    "\n",
    "true_result = cross_entropy(a,tl)\n",
    "false_result = cross_entropy(a,fl)\n",
    "\n",
    "print(true_result)\n",
    "print(false_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "11604b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(train_loader):\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        \n",
    "        # 이미지와 label를 1개로 만듬\n",
    "        image = image[0]\n",
    "        label = label[0]\n",
    "        \n",
    "        image = image.view(-1, 28 * 28)\n",
    "        print(image.size())\n",
    "        \n",
    "        # Weight(가중치)를 초기화 (torch rand 함수 이용, 도중에 빼기 0.5를 하여 함수값이 -0.5~0.5 사이로 만드세요)\n",
    "        W_ih = torch.rand(28*28, 100, dtype = torch.float) - 0.5\n",
    "        W_ho = torch.rand(100, 10, dtype = torch.float) - 0.5\n",
    "        \n",
    "        # Forward propagration 계산하기.\n",
    "        \n",
    "        # 첫번째 Layer의 값\n",
    "        outputs = image.matmul(W_ih)\n",
    "        \n",
    "        # 결과 값(outputs)을 ReLU 함수에 적용하기\n",
    "        outputs = ReLU_func(outputs)\n",
    "        \n",
    "        # 출력 layer 계산 하기\n",
    "        outputs = outputs.matmul(W_ho)\n",
    "        \n",
    "        # softmax 하기\n",
    "        softmaxed_outputs = softmax(outputs)\n",
    "        pred = torch.argmax(softmaxed_outputs,dim=1)\n",
    "        print(pred)\n",
    "        train_correct = (pred == y_train).float().mean()\n",
    "        print(train_correct)\n",
    "    \n",
    "        \n",
    "             \n",
    "        # label 값을 one_hot 형태로 변환하기\n",
    "        expected_outputs = one_hot_encoding(label)\n",
    "        \n",
    "        #loss 값 구하기\n",
    "        loss = cross_entropy(softmaxed_outputs, expected_outputs)\n",
    "        print(loss)\n",
    "        loss = (loss - BATCH_SIZE).pow(2).sum()\n",
    "        print(loss.item())\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d73d05eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 784])\n",
      "tensor([5])\n",
      "0.0625\n",
      "tensor([0.1331])\n",
      "1015.5020751953125\n"
     ]
    }
   ],
   "source": [
    "forward_pass(train_loader) # 결과물이 맞다면 아래와 같은 값이 나오게 됩니다. 단, 2번째 줄의 값은 변동 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f64cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
